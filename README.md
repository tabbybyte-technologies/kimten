# üêà kimten

A micro-agent library: thin wrapper over the **[Agent interface in Vercel AI SDK Core v6+](https://ai-sdk.dev/docs/agents)** 

Small surface area, sharp claws, zero fluff (well‚Ä¶ almost).

Think:

> minimal agent loop + tools + short-term memory  
> but delivered as a smol terminal cat üêæ

Kimten doesn‚Äôt try to be a ‚Äúframework‚Äù.  
It‚Äôs just a neat little helper that runs prompts, calls tools, remembers a little, and gets out of your way.

No planners.  
No graphs.  
No magic state machines.  
Just *play ‚Üí result ‚Üí nap*. üòº

---

## ‚ú® Why Kimten?

Sometimes you don‚Äôt want:

- 15 abstractions
- 6 middlewares
- 4 ‚Äúagent runtimes‚Äù
- 200MB of dependencies

You just want:

‚úî call an LLM  
‚úî give it tools  
‚úî keep a bit of convo memory  
‚úî maybe get structured output  
‚úî done

Kimten = **tiny agent loop with paws** üêæ

Perfect for:

- CLI helpers
- small automations
- local tools
- scripting
- quick AI utilities
- ‚Äújust let the model call a function‚Äù use cases

---

## üì¶ Install

Feed the cat some treats:

```bash
npm i @tabbybyte/kimten ai zod @ai-sdk/openai
```

That‚Äôs it. No ceremony. No rituals. üçó

### Requirements

- Node `>=22`
- AI SDK Core `>=6`
- Zod `>=3`

---

## üöÄ Usage

Summon your little helper (with or without `toys`) and let it `play`.

```js
import { openai } from '@ai-sdk/openai'; // or, any other provider
import { z } from 'zod';
import Kimten from '@tabbybyte/kimten';

const cat = Kimten({
  brain: openai('gpt-4o-mini'), // or, any other available model

  toys: {
    add: async ({ a, b }) => a + b,
  },

  personality: 'Helpful terminal cat',

  hops: 10,
});

// free-form text
const text = await cat.play('summarize this repo');

// structured output
const structured = await cat.play(
  'extract the name',
  z.object({ name: z.string() })
);

// wipe short-term memory
cat.forget();
```

Done.  
No lifecycle hooks. No config jungle. üßò

---

## üß† Mental Model

Kimten is basically:

```
loop:
  include short-term conversation memory
  prompt LLM
  maybe call a tool
  repeat (max hops)
return result
```

That‚Äôs the whole thing.

Each instance keeps a **small, short-term chat memory** üß†  
So follow-up prompts naturally reference earlier messages:

> ‚Äúsummarize this‚Äù ‚Üí ‚Äúmake it shorter‚Äù ‚Üí ‚Äúnow extract bullets‚Äù

When you‚Äôre done, call `forget()` and the brain goes blank again. ü´ß

It‚Äôs intentionally:

* tiny
* predictable
* hackable
* easy to read in one sitting

If you can read the source in ~5 minutes, we did it right üò∫

---

## ‚öôÔ∏è API

### `Kimten(config)`

Create a new cat.

### Required (must-haves)

* `brain` ‚Üí AI SDK model instance  

### Optional (extra whiskers)

* `toys` ‚Üí object map of tool definitions. Each entry can be:
  * async function shorthand: `async (args) => result`
  * object form: `{ inputSchema?, description?, strict?, execute }`
  default: `{}`
* `personality` ‚Üí system prompt / behavior description (default: `"You are a helpful assistant."`)
* `hops` ‚Üí max agent loop steps (default: `10`)  
  prevents infinite zoomies üåÄ

### Tool semantics (important)

- Tool inputs are validated only if you provide `inputSchema` (shorthand tools accept anything).
- Tool results should be JSON-serializable; `undefined` becomes `null`.
- If a tool throws, Kimten returns `{ error, toolName }` as the tool result (it does not re-throw).

### Returns

* `play(input, schema?)`

  * runs the agent  
  * uses short-term memory automatically  
  * optional Zod schema for structured output

* `forget()`

  * clears short-term memory/context

---

## üß© Design Philosophy & Vibes

Kimten intentionally avoids ‚Äúbig agent framework energy‚Äù.

It‚Äôs meant to be:

* small
* opinionated
* dependency-light
* short-term memory by design
* easy to embed anywhere

No:

* streaming APIs
* planners or graphs
* middleware/plugins
* long-term memory
* persistence/storage
* hidden background processes
* TypeScript runtime/build nonsense
* full fledged orchestration system

If you need those‚Ä¶ use something heavier.

If you want **simple + fast + composable**, Kimten fits nicely.

---

## üõ† Tips

### Providers & models

For the `brain` part, feel free to use any compatible provider and their models.

Refer to https://ai-sdk.dev/docs/foundations/providers-and-models

### Add tools freely

Tools can stay simple:

```js
toys: {
  readFile,
  writeFile,
  fetchJson,
  runCommand,
}
```

The model decides when to use them.

For stronger arg validation and better tool selection, use object form:

```js
import { z } from 'zod';

toys: {
  add: {
    description: 'Add two numbers.',
    inputSchema: z.object({ a: z.number(), b: z.number() }),
    async execute({ a, b }) {
      return a + b;
    },
  },
}
```

### Small ‚Äúreal‚Äù example

```js
toys: {
  fetchJson: {
    description: 'Fetch JSON from a URL (GET).',
    inputSchema: z.object({ url: z.string().url() }),
    async execute({ url }) {
      const res = await fetch(url);
      if (!res.ok) throw new Error(`HTTP ${res.status}`);
      return res.json();
    },
  },
}
```

### Structured output = sanity

Use Zod schemas whenever possible.  
LLMs lie less when types exist üòº

### Keep hops low

If you need 50+ steps, you probably want a planner, not Kimten.

### Reset when needed

Fresh task? Call `forget()`.  
Cats don‚Äôt hold grudges (or context). üêæ

---

## License

MIT  
Pet responsibly.
